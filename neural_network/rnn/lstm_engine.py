#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@Time Â  Â : 2025/06/21 10:38
@Author Â : weiyutao
@File Â  Â : lstm_engine.py
"""

"""
LSTMå¼‚å¸¸æ£€æµ‹å¼•æ“ - æ”¯æŒå®æ—¶å•æ¡æ•°æ®æ¨ç†
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from typing import Union, Tuple, Optional, List
import joblib
import logging
from pathlib import Path


from .auto_encoders import RecurrentAutoencoder


class LSTMEngine:
    """
    LSTMå¼‚å¸¸æ£€æµ‹å¼•æ“
    æ”¯æŒåŠ è½½ä¸åŒçš„LSTMæ¨¡å‹å’Œå½’ä¸€åŒ–å™¨ï¼Œè¿›è¡Œå®æ—¶å•æ¡æ•°æ®å¼‚å¸¸æ£€æµ‹
    """
    
    def __init__(
        self, 
        model_class,
        model_params: dict,
        seq_len: int = 20,
        n_features: int = 6,
        device: str = "auto",
        threshold: float = 0.5,
        threshold_method: str = "fixed",
        normalized_flag: int = 1
    ):
        """
        åˆå§‹åŒ–LSTMå¼•æ“
        
        Args:
            model_class: æ¨¡å‹ç±»ï¼ˆå¦‚RecurrentAutoencoderï¼‰
            model_params: æ¨¡å‹å‚æ•°å­—å…¸
            seq_len: åºåˆ—é•¿åº¦
            n_features: ç‰¹å¾æ•°é‡
            device: è®¾å¤‡é€‰æ‹© ("auto", "cpu", "cuda")
            threshold: å¼‚å¸¸æ£€æµ‹é˜ˆå€¼
            threshold_method: é˜ˆå€¼æ–¹æ³• ("fixed", "adaptive")
        """
        self.model_class = model_class
        self.model_params = model_params
        self.seq_len = seq_len
        self.n_features = n_features
        self.threshold = threshold
        self.threshold_method = threshold_method
        self.normalized_flag = normalized_flag
        
        # è®¾å¤‡é…ç½®
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.model = None
        self.scaler = None
        self.is_loaded = False
        
        # æ—¥å¿—é…ç½®
        self.logger = logging.getLogger(self.__class__.__name__)
        
        print(f"ğŸ¤– LSTMå¼•æ“åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   åºåˆ—é•¿åº¦: {seq_len}, ç‰¹å¾æ•°: {n_features}")
        print(f"   é˜ˆå€¼: {threshold} ({threshold_method})")
    
    def load_model(self, model_path: str) -> bool:
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not Path(model_path).exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            self.model = self.model_class(**self.model_params)
            
            # åŠ è½½æ¨¡å‹çŠ¶æ€
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.to(self.device)
            self.model.eval()
            
            best_loss = checkpoint.get('best_loss', 'N/A')
            self.logger.info(f"æ¨¡å‹åŠ è½½æˆåŠŸ! æœ€ä½³æŸå¤±: {best_loss}")
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ! æœ€ä½³æŸå¤±: {best_loss}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def load_scaler(self, scaler_path: Optional[str] = None, scaler_obj: Optional[StandardScaler] = None) -> bool:
        """
        åŠ è½½å½’ä¸€åŒ–å™¨
        
        Args:
            scaler_path: å½’ä¸€åŒ–å™¨æ–‡ä»¶è·¯å¾„
            scaler_obj: ç›´æ¥ä¼ å…¥çš„å½’ä¸€åŒ–å™¨å¯¹è±¡
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            if scaler_obj is not None:
                # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„scalerå¯¹è±¡
                self.scaler = scaler_obj
                print("âœ… ä½¿ç”¨ä¼ å…¥çš„å½’ä¸€åŒ–å™¨å¯¹è±¡")
                
            elif scaler_path is not None:
                # ä»æ–‡ä»¶åŠ è½½scaler
                if not Path(scaler_path).exists():
                    raise FileNotFoundError(f"å½’ä¸€åŒ–å™¨æ–‡ä»¶ä¸å­˜åœ¨: {scaler_path}")
                
                self.scaler = joblib.load(scaler_path)
                print(f"âœ… ä»æ–‡ä»¶åŠ è½½å½’ä¸€åŒ–å™¨: {scaler_path}")
                
            else:
                # åˆ›å»ºé»˜è®¤çš„scalerï¼ˆéœ€è¦åç»­fitï¼‰
                self.scaler = StandardScaler()
                print("âš ï¸  åˆ›å»ºäº†é»˜è®¤å½’ä¸€åŒ–å™¨ï¼Œéœ€è¦åç»­ä½¿ç”¨æ•°æ®è¿›è¡Œfit")
            
            # éªŒè¯scaler
            if hasattr(self.scaler, 'n_features_in_') and self.scaler.n_features_in_ != self.n_features:
                print(f"âš ï¸  å½’ä¸€åŒ–å™¨ç‰¹å¾æ•°({self.scaler.n_features_in_})ä¸é¢„æœŸ({self.n_features})ä¸åŒ¹é…")
            
            return True
            
        except Exception as e:
            self.logger.error(f"å½’ä¸€åŒ–å™¨åŠ è½½å¤±è´¥: {str(e)}")
            print(f"âŒ å½’ä¸€åŒ–å™¨åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    
    def setup(self, model_path: str, scaler_path: Optional[str] = None, scaler_obj: Optional[StandardScaler] = None) -> bool:
        """
        ä¸€é”®è®¾ç½®ï¼šåŠ è½½æ¨¡å‹å’Œå½’ä¸€åŒ–å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            scaler_path: å½’ä¸€åŒ–å™¨æ–‡ä»¶è·¯å¾„
            scaler_obj: ç›´æ¥ä¼ å…¥çš„å½’ä¸€åŒ–å™¨å¯¹è±¡
            
        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        print("ğŸ”§ å¼€å§‹è®¾ç½®LSTMå¼•æ“...")
        try:
            # åŠ è½½æ¨¡å‹
            model_loaded = self.load_model(model_path)
            if not model_loaded:
                return False
            
            # åŠ è½½å½’ä¸€åŒ–å™¨
            scaler_loaded = self.load_scaler(scaler_path, scaler_obj) if self.normalized_flag else None
            if not scaler_loaded and self.normalized_flag:
                return False
            
            self.is_loaded = True
            print("ğŸ‰ LSTMå¼•æ“è®¾ç½®å®Œæˆï¼Œready for inference!")
        except Exception as e:
            raise ValueError(f"Fial to load setup function! {str(e)}") from e
        return True
    
    def _validate_input(self, data: Union[list, tuple, np.ndarray]) -> np.ndarray:
        """
        éªŒè¯å’Œè½¬æ¢è¾“å…¥æ•°æ®
        
        Args:
            data: è¾“å…¥æ•°æ®
            
        Returns:
            np.ndarray: éªŒè¯åçš„æ•°æ®
        """
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(data, (list, tuple)):
            data = np.array(data)
        elif not isinstance(data, np.ndarray):
            raise TypeError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {type(data)}")
        
        # æ£€æŸ¥ç»´åº¦
        if data.ndim == 1:
            if len(data) != self.n_features:
                raise ValueError(f"ç‰¹å¾æ•°ä¸åŒ¹é…: æœŸæœ›{self.n_features}, å®é™…{len(data)}")
            data = data.reshape(1, -1)  # (1, n_features)
        elif data.ndim == 2:
            if data.shape[1] != self.n_features:
                raise ValueError(f"ç‰¹å¾æ•°ä¸åŒ¹é…: æœŸæœ›{self.n_features}, å®é™…{data.shape[1]}")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç»´åº¦: {data.ndim}, æœŸæœ›1æˆ–2ç»´")
        
        return data
    
    def _normalize_data(self, data: np.ndarray) -> np.ndarray:
        """
        å½’ä¸€åŒ–æ•°æ®
        
        Args:
            data: åŸå§‹æ•°æ® (n_samples, n_features)
            
        Returns:
            np.ndarray: å½’ä¸€åŒ–åçš„æ•°æ®
        """
        if self.scaler is None:
            raise ValueError("å½’ä¸€åŒ–å™¨æœªåŠ è½½")
        
        # å¦‚æœscaleræœªfitï¼ŒæŠ›å‡ºè­¦å‘Š
        if not hasattr(self.scaler, 'mean_'):
            raise ValueError("å½’ä¸€åŒ–å™¨æœªè¿›è¡Œfitæ“ä½œ")
        
        return self.scaler.transform(data)
    
    def _compute_reconstruction_error(self, original: torch.Tensor, reconstructed: torch.Tensor) -> float:
        """
        è®¡ç®—é‡æ„è¯¯å·®
        
        Args:
            original: åŸå§‹æ•°æ®
            reconstructed: é‡æ„æ•°æ®
            
        Returns:
            float: é‡æ„è¯¯å·®
        """
        # ä½¿ç”¨MSEä½œä¸ºé‡æ„è¯¯å·®
        # mse = torch.nn.functional.mse_loss(reconstructed, original, reduction='mean')
        # return mse.item()
        
        """
        ç»„åˆè¯¯å·®è®¡ç®—ï¼Œæé«˜åŒºåˆ†åº¦
        """
        # MSE * 1000
        mse_scaled = torch.nn.functional.mse_loss(reconstructed, original, reduction='mean') * 1000
        
        # MAE * 100  
        mae_scaled = torch.nn.functional.l1_loss(reconstructed, original, reduction='mean') * 100
        
        # è¿”å›ç»„åˆåˆ†æ•°
        return mse_scaled.item() + mae_scaled.item()



    def predict(
        self, 
        data: Union[list, tuple, np.ndarray], 
        return_details: bool = False,
    ) -> Union[bool, Tuple[bool, dict]]:
        """
        å•æ¡æ•°æ®å¼‚å¸¸æ£€æµ‹é¢„æµ‹
        
        Args:
            data: è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_features,) æˆ– (seq_len, n_features)
            return_details: æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯
            
        Returns:
            bool: æ˜¯å¦å¼‚å¸¸ (return_details=Falseæ—¶)
            Tuple[bool, dict]: (æ˜¯å¦å¼‚å¸¸, è¯¦ç»†ä¿¡æ¯) (return_details=Trueæ—¶)
        """
        if not self.is_loaded:
            raise RuntimeError("æ¨¡å‹æˆ–å½’ä¸€åŒ–å™¨æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨setup()æ–¹æ³•")
        
        try:
            # 1. æ•°æ®éªŒè¯å’Œè½¬æ¢
            data = self._validate_input(data)
            
            sequence_data = data
            
            # 3. å½’ä¸€åŒ–
            
            normalized_data = self._normalize_data(sequence_data) if self.normalized_flag else sequence_data # (seq_len, n_features)

            
            # 4. è½¬æ¢ä¸ºPyTorchå¼ é‡
            input_tensor = torch.FloatTensor(normalized_data).unsqueeze(0).to(self.device)  # (1, seq_len, n_features)
            
            # 5. æ¨¡å‹æ¨ç†
            with torch.no_grad():
                reconstructed = self.model(input_tensor)  # (1, seq_len, n_features)
            
            # 6. è®¡ç®—é‡æ„è¯¯å·®
            reconstruction_error = self._compute_reconstruction_error(input_tensor, reconstructed)
            
            # 7. å¼‚å¸¸åˆ¤æ–­
            is_anomaly = reconstruction_error > self.threshold
            
            # 8. å‡†å¤‡è¯¦ç»†ä¿¡æ¯
            # details = {
            #     'reconstruction_error': reconstruction_error,
            #     'threshold': self.threshold,
            #     'is_anomaly': is_anomaly,
            #     'input_shape': data.shape,
            #     'normalized_input': normalized_data,
            #     'reconstructed_output': reconstructed.cpu().numpy()
            # }
            
            # 9. è¿”å›ç»“æœ
            if return_details:
                return is_anomaly, reconstruction_error
            else:
                return is_anomaly
                
        except Exception as e:
            self.logger.error(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}")
            raise RuntimeError(f"é¢„æµ‹å¤±è´¥: {str(e)}")
    
    def update_threshold(self, new_threshold: float):
        """æ›´æ–°å¼‚å¸¸æ£€æµ‹é˜ˆå€¼"""
        self.threshold = new_threshold
        print(f"âœ… é˜ˆå€¼å·²æ›´æ–°ä¸º: {new_threshold}")
    
    def get_status(self) -> dict:
        """è·å–å¼•æ“çŠ¶æ€"""
        return {
            'model_loaded': self.model is not None,
            'scaler_loaded': self.scaler is not None,
            'is_ready': self.is_loaded,
            'device': str(self.device),
            'seq_len': self.seq_len,
            'n_features': self.n_features,
            'threshold': self.threshold,
            'threshold_method': self.threshold_method
        }


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•ä»£ç 
if __name__ == "__main__":
    
    def test_lstm_engine():
        """æµ‹è¯•LSTMå¼•æ“"""
        print("ğŸ§ª æµ‹è¯•LSTMå¼•æ“")
        print("=" * 50)
        
        # 1. åˆå§‹åŒ–å¼•æ“
        model_params = {
            'seq_len': 60,
            'n_features': 7,
            'embedding_dim': 128
        }
        
        engine = LSTMEngine(
            model_class=RecurrentAutoencoder,
            model_params=model_params,
            seq_len=60,
            n_features=7,
            threshold=0.5
        )
        engine.setup(model_path='/work/ai/WHOAMI/whoami/neural_network/rnn/checkpoint_epoch_148.pth', scaler_path='/work/ai/WHOAMI/whoami/neural_network/rnn/training_scaler.pkl')
        # 3. è®¾ç½®å¼•æ“ï¼ˆè¿™é‡Œè·³è¿‡æ¨¡å‹åŠ è½½ï¼Œå› ä¸ºæ²¡æœ‰çœŸå®çš„æ¨¡å‹æ–‡ä»¶ï¼‰
        
        # 4. æµ‹è¯•é¢„æµ‹ï¼ˆéœ€è¦çœŸå®æ¨¡å‹æ‰èƒ½å·¥ä½œï¼‰
        test_data = np.random.randn(60, 7)  # å•æ¡æ•°æ®
        print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
        print(f"æµ‹è¯•æ•°æ®: {test_data}")
        result = engine.predict(data=test_data, return_details=True)
        print(f"result: {result}")
    
    # è¿è¡Œæµ‹è¯•
    test_lstm_engine()