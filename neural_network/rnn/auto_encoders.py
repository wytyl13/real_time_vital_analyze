
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@Time Â  Â : 2025/06/20 10:07
@Author Â : weiyutao
@File Â  Â : auto_encoders.py

original parameter update: w_new = w_old - lr * gradient
weight decay: w_new = (1 - lr * Î») * w_old - lr * gradient, 
    Î»æƒé‡è¡°å‡ç³»æ•°ï¼Œè¶Šå¤§æƒé‡è¢«å‹ç¼©çš„è¶Šå‰å®³
     (1 - lr * Î»)ï¼Œæƒé‡è¡°å‡å› å­ï¼Œæ¯æ¬¡éƒ½è®©æƒé‡ç¨å¾®ç¼©å°çš„ç³»æ•°ï¼Œæ€»æ˜¯å°äº1
     weight decayç›´æ¥åœ¨åå‘ä¼ æ’­æ›´æ–°æƒé‡çš„æ—¶å€™èµ·ä½œç”¨ï¼Œåœ¨æ¨ç†çš„æ—¶å€™é—´æ¥èµ·ä½œç”¨ï¼ˆå› ä¸ºæ¨ç†çš„æ—¶å€™ä½¿ç”¨çš„æ˜¯weight decayå½±å“è¿‡çš„æƒé‡ï¼‰
dropoutï¼šä½œç”¨äºå‰å‘ä¼ æ’­çš„è¾“å‡ºï¼Œä¸€èˆ¬ä½œç”¨äºdenseå±‚
    output = w1Ã—h1 + w2Ã—h2 + w3Ã—h3
    âˆ‚output/âˆ‚w2 = h2
    
    [h1, h2, h3] = [2.0, 1.5, 3.0]
    å¦‚æœdropoutå°†å‰ä¸€å±‚çš„è¾“å‡ºh2ç½®ä¸º0
    [h1, h2, h3] = [2.0, 0, 3.0]
    output = w1Ã—h1 + w2Ã—0 + w3Ã—h3
    âˆ‚output/âˆ‚w2 = 0    
    é—´æ¥é€ æˆw2åœ¨æœ¬æ¬¡åå‘ä¼ æ’­ä¸­ä¸è¢«æ›´æ–°ï¼Œå› æ­¤dropoutåªä¼šåœ¨è®­ç»ƒçš„é¢æ—¶å€™æœ‰å½±å“ï¼Œä¸ä¼šé—´æ¥ä½œç”¨äºå‰å‘ä¼ æ’­æ¨ç†çš„æ—¶å€™
"""

import torch
import torch.nn as nn
import copy
import numpy as np
import pandas as pd
import time
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from torch.utils.data import DataLoader, TensorDataset
from torch.optim.lr_scheduler import ReduceLROnPlateau



device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class Encoder(nn.Module):
    """
    å®šä¹‰ä¸€ä¸ªç¼–ç å™¨çš„å­ç±»ï¼Œç»§æ‰¿çˆ¶ç±» nn.Module
    """
    def __init__(
        self, 
        seq_len, 
        n_features, 
        embedding_dim=64,
        dropout=0.2
    ):
        super(Encoder, self).__init__()
 
        self.seq_len, self.n_features = seq_len, n_features
        self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim
        self.dropout = nn.Dropout(dropout) # ç¼–ç å™¨ä½¿ç”¨è¾ƒå¤§çš„æ­£åˆ™åŒ–æ–¹æ¡ˆ
        # ä½¿ç”¨åŒå±‚LSTM
        self.rnn1 = nn.LSTM(
          input_size=n_features,
          hidden_size=self.hidden_dim,
          num_layers=1,
          batch_first=True)
    
        self.rnn2 = nn.LSTM(
          input_size=self.hidden_dim,
          hidden_size=embedding_dim,
          num_layers=1,
          batch_first=True)

 
    def forward(self, x):
        # x (seq_len, n_features) - (60, 7)
        # x = x.reshape((1, self.seq_len, self.n_features)) # (batch, seq_len, n_features) - (1, 60, 7)
        x, (_, _) = self.rnn1(x) 
        # print(f"encoder rnn1 - x ----------- {x.shape}") # output_x - (batch, seq_len, hidden_size) - (1, 60, self.hidden_dim)
        x, (hidden_n, _) = self.rnn2(x) 
        # print(f"encoder rnn2 - x ----------- {x.shape}") # output_x - (batch, seq_len, hidden_size) - (1, 60, self.embedding_dim)  
        # print(f"encoder rnn2 - hidden_n ----------- {hidden_n.shape}") # hidden_n - (num_layers, batch_size, hidden_size) - (1, 1, self.embedding_dim)
        
        return hidden_n[-1] # å»æœ€åä¸€å±‚éšè—å±‚ä½œä¸ºè§£ç å™¨çš„è¾“å…¥

class Decoder(nn.Module):
    """
    å®šä¹‰ä¸€ä¸ªè§£ç å™¨çš„å­ç±»ï¼Œç»§æ‰¿çˆ¶ç±» nn.Modul
    """
    def __init__(
        self, 
        seq_len, 
        input_dim=64, 
        n_features=1,
        dropout=0.1
    ):
        super(Decoder, self).__init__()
 
        self.seq_len, self.input_dim = seq_len, input_dim
        self.hidden_dim, self.n_features = 2 * input_dim, n_features
        self.dropout = nn.Dropout(dropout) # è§£ç å™¨ä½¿ç”¨æ›´å°çš„æ­£åˆ™åŒ–æ–¹æ¡ˆ
        self.rnn1 = nn.LSTM(
          input_size=input_dim,
          hidden_size=input_dim,
          num_layers=1,
          batch_first=True)
 
        self.rnn2 = nn.LSTM(
          input_size=input_dim,
          hidden_size=self.hidden_dim,
          num_layers=1,
          batch_first=True)
        self.output_layer = nn.Linear(self.hidden_dim, n_features)

 
    def forward(self, x):
        # x in decode is the last layer of n_hidden in encoder. (batch_size, hidden_size) - (1, self.embedding_dim)  
        # print(f"the shape of x in decoder --------  {x.shape}")
        x = x.unsqueeze(1).repeat(1, self.seq_len, 1)
        # print(f"the changed x in decoder --------  {x.shape}")
        x, (hidden_n, cell_n) = self.rnn1(x)
        # print(f"decoder rnn1 x -------------- {x.shape}")
        
        x, (hidden_n, cell_n) = self.rnn2(x)
        # print(f"decoder rnn2 x -------------- {x.shape}")

        x = self.output_layer(x)
        # print(f"decoder output_layer x -------------- {x.shape}")
        return x


def preprocess_inference_data(data, seq_len, n_features, scaler, slide_window_flag=1):
    """
    é¢„å¤„ç†æ¨ç†æ•°æ®
    
    Args:
        data: åŸå§‹æ•°æ® (pandas DataFrame æˆ– numpy array)
        seq_len: åºåˆ—é•¿åº¦
        n_features: ç‰¹å¾æ•°é‡
        scaler: å½’ä¸€åŒ–å™¨
        slide_window_flag: æ˜¯å¦ä½¿ç”¨æ»‘åŠ¨çª—å£
    
    Returns:
        tensor_data: é¢„å¤„ç†åçš„å¼ é‡æ•°æ®
        scaler: å½’ä¸€åŒ–å™¨
        original_shape: åŸå§‹æ•°æ®å½¢çŠ¶
    """
    if isinstance(data, pd.DataFrame):
        data = data.values
    
    original_shape = data.shape
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {original_shape}")
    
    # åˆ›å»ºåºåˆ—æ•°æ®
    if slide_window_flag:
        sequences = []
        for i in range(len(data) - seq_len + 1):
            sequences.append(data[i:i + seq_len])
        sequence_data = np.array(sequences)
    else:
        # éæ»‘åŠ¨çª—å£ï¼Œç›´æ¥åˆ†å‰²
        n_sequences = len(data) // seq_len
        sequence_data = data[:n_sequences * seq_len].reshape(n_sequences, seq_len, n_features)
    
    print(f"åºåˆ—æ•°æ®å½¢çŠ¶: {sequence_data.shape}")
    
    # å½’ä¸€åŒ–
    seq_shape = sequence_data.shape
    reshaped_data = sequence_data.reshape(-1, seq_shape[-1])  # (n_samples * seq_len, n_features)
    
    if scaler is not None:
        normalized_data = scaler.transform(reshaped_data)
    else:
        # å¦‚æœæ²¡æœ‰æä¾›scalerï¼Œåˆ›å»ºæ–°çš„
        scaler = StandardScaler()
        normalized_data = scaler.fit_transform(reshaped_data)
    
    # é‡æ–°reshapeå›åºåˆ—å½¢çŠ¶
    normalized_sequences = normalized_data.reshape(seq_shape)
    
    # è½¬æ¢ä¸ºtensor
    tensor_data = torch.FloatTensor(normalized_sequences)
    
    return tensor_data, scaler, original_shape


def create_inference_dataloader(data, batch_size=32, shuffle=False):
    """
    åˆ›å»ºæ¨ç†ç”¨çš„DataLoader
    
    Args:
        data: é¢„å¤„ç†åçš„tensoræ•°æ®
        batch_size: æ‰¹æ¬¡å¤§å°
        shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
    
    Returns:
        DataLoader
    """
    dataset = TensorDataset(data, data)  # è‡ªåŠ¨ç¼–ç å™¨è¾“å…¥=è¾“å‡º
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)
    return dataloader


def batch_inference(model, dataloader, device, return_errors=True):
    """
    æ‰¹æ¬¡æ¨ç†
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        dataloader: æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        return_errors: æ˜¯å¦è¿”å›é‡æ„è¯¯å·®
    
    Returns:
        reconstructed_data: é‡æ„æ•°æ®
        reconstruction_errors: é‡æ„è¯¯å·®ï¼ˆå¯é€‰ï¼‰
        raw_errors: åŸå§‹è¯¯å·®ï¼ˆæ¯ä¸ªæ—¶é—´æ­¥æ¯ä¸ªç‰¹å¾çš„è¯¯å·®ï¼‰
    """
    model.eval()
    all_reconstructed = []
    all_errors = []
    all_raw_errors = []
    
    with torch.no_grad():
        for batch_data, _ in dataloader:
            batch_data = batch_data.to(device)
            
            # å‰å‘ä¼ æ’­
            reconstructed = model(batch_data)
            
            # è®¡ç®—é‡æ„è¯¯å·®
            if return_errors:
                # é€ç‚¹è¯¯å·®ï¼šL1è·ç¦»
                raw_error = torch.abs(batch_data - reconstructed)
                # åºåˆ—çº§è¯¯å·®ï¼šæ¯ä¸ªåºåˆ—çš„å¹³å‡è¯¯å·®
                sequence_error = raw_error.mean(dim=(1, 2))  # (batch_size,)
                
                all_raw_errors.append(raw_error.cpu().numpy())
                all_errors.append(sequence_error.cpu().numpy())
            
            all_reconstructed.append(reconstructed.cpu().numpy())
    
    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
    reconstructed_data = np.concatenate(all_reconstructed, axis=0)
    
    if return_errors:
        reconstruction_errors = np.concatenate(all_errors, axis=0)
        raw_errors = np.concatenate(all_raw_errors, axis=0)
        return reconstructed_data, reconstruction_errors, raw_errors
    else:
        return reconstructed_data


def create_data_loaders(train_data, val_data, batch_size=32):
    """
    åˆ›å»ºDataLoader
    """
    # åˆ›å»ºTensorDatasetï¼ˆè‡ªåŠ¨ç¼–ç å™¨çš„è¾“å…¥å’Œç›®æ ‡æ˜¯ç›¸åŒçš„ï¼‰
    train_dataset = TensorDataset(train_data, train_data)
    val_dataset = TensorDataset(val_data, val_data)
    
    # åˆ›å»ºDataLoader
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    return train_loader, val_loader


def train_model(
    model, 
    train_loader, 
    val_loader, 
    n_epochs,
    lr=1e-4,
    patience=10,
    lr_scheduler=True,
    save_checkpoints=True
):
    optimizer = torch.optim.Adam(
        model.parameters(), 
        lr=lr,
        weight_decay=1e-4
    )
    criterion = nn.L1Loss(reduction='mean').to(device)
    if lr_scheduler:
        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, 
                                    patience=patience//2, verbose=True)
    
    
    history = dict(train=[], val=[], lr=[])
    best_model_wts = copy.deepcopy(model.state_dict())
    best_loss = float('inf')
    patience_counter = 0
    print(f"å¼€å§‹è®­ç»ƒ: {n_epochs} epochs, å­¦ä¹ ç‡: {lr}, æ—©åœè€å¿ƒåº¦: {patience}")
    print("=" * 70)
  
    for epoch in range(1, n_epochs + 1):
        # =================== è®­ç»ƒé˜¶æ®µ ===================
        model = model.train()
        train_losses = []
        
        # è®­ç»ƒé˜¶æ®µæ—¶é—´æ§åˆ¶
        last_update_time = 0
        
        for batch_idx, (batch_data, _) in enumerate(train_loader):
            optimizer.zero_grad()
            batch_data = batch_data.to(device)
            # print(f"batch_data ------------- {batch_data.shape}")
            reconstructed = model(batch_data)
            # print(f"reconstructed ------------- {reconstructed.shape}")
 
            loss = criterion(reconstructed, batch_data)
            # åŸåœ°æ›´æ–°æ˜¾ç¤º
            # æ¯ç§’æ›´æ–°ä¸€æ¬¡æ˜¾ç¤º
            current_time = time.time()
            if current_time - last_update_time >= 1.0:  # 1ç§’é—´éš”
                print(f"\rEpoch {epoch} [{batch_idx+1}/{len(train_loader)}] Train Loss: {loss.item():.4f}", end='')
                last_update_time = current_time
                
            loss.backward()
            optimizer.step()
            train_losses.append(loss.item())
 
        # ç¡®ä¿æœ€åä¸€ä¸ªbatchçš„æŸå¤±ä¹Ÿæ˜¾ç¤º
        print(f"\rEpoch {epoch} [{len(train_loader)}/{len(train_loader)}] Train Loss: {train_losses[-1]:.4f}", end='', flush=True)
 
 
        # =================== éªŒè¯é˜¶æ®µ ===================
        val_losses = []
        model = model.eval()
        with torch.no_grad():
            for batch_idx, (batch_data, _) in enumerate(val_loader):
                batch_data = batch_data.to(device)
                reconstructed = model(batch_data)
 
                loss = criterion(reconstructed, batch_data)
                # æ¯ç§’æ›´æ–°ä¸€æ¬¡éªŒè¯æŸå¤±æ˜¾ç¤º
                current_time = time.time()
                if current_time - last_update_time >= 1.0:  # 1ç§’é—´éš”
                    print(f"\rEpoch {epoch} - Validation [{batch_idx+1}/{len(val_loader)}] Val Loss: {loss.item():.4f}", end='', flush=True)
                    last_update_time = current_time
                val_losses.append(loss.item())
 
        # =================== è®°å½•å’Œè°ƒåº¦ ===================
        train_loss = np.mean(train_losses)
        val_loss = np.mean(val_losses)
        current_lr = optimizer.param_groups[0]['lr']

        history['train'].append(train_loss)
        history['val'].append(val_loss)
        history['lr'].append(current_lr)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        if lr_scheduler:
            scheduler.step(val_loss)
 
        if val_loss < best_loss:
            best_loss = val_loss
            best_model_wts = copy.deepcopy(model.state_dict())
            patience_counter = 0
            improvement = " â­ NEW BEST!"
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if save_checkpoints:
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_loss': best_loss,
                    'history': history
                }, f'checkpoint_epoch_{epoch}.pth')
        else:
            patience_counter += 1
            improvement = ""

        print(f'\nEpoch {epoch}: train loss {train_loss} val loss {val_loss}')
        
        if patience_counter >= patience:
            print(f"\nğŸ›‘ Early stopping at epoch {epoch} (patience: {patience})")
            break
        
        
    model.load_state_dict(best_model_wts)
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.6f}")
    return model.eval(), history

class RecurrentAutoencoder(nn.Module):
    """
    å®šä¹‰ä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨çš„å­ç±»ï¼Œç»§æ‰¿çˆ¶ç±» nn.Module
    å¹¶ä¸”è‡ªåŠ¨ç¼–ç å™¨é€šè¿‡ç¼–ç å™¨å’Œè§£ç å™¨ä¼ é€’è¾“å…¥
    """
    def __init__(self, seq_len, n_features, embedding_dim=64):
        super(RecurrentAutoencoder, self).__init__()
        self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)
        self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)
 
    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x


def create_sequences(data, seq_length, n_features, slide_window_flag: int = 0):
    try:
        if slide_window_flag:
            sequences = []
            for i in range(len(data) - seq_length + 1):
                sequences.append(data[i:i + seq_length])
            return np.array(sequences)
        n_sequences = len(data) // seq_len
        n_samples_needed = n_sequences * seq_len 
        data = data[:n_samples_needed]
        data = data.reshape((n_sequences, seq_len, n_features))
        return data   
    except Exception as e:
        raise ValueError("Fail to exec create_sequences function!") from e


def time_series_split(data, train_ratio=0.8):
    """
    æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²æ•°æ®
    é€‚ç”¨äºæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹
    """
    n_samples = len(data)
    split_idx = int(n_samples * train_ratio)
    
    train_data = data[:split_idx]
    val_data = data[split_idx:]
    
    return train_data, val_data


def normalize_data(train_data, val_data, method='standard'):
    """
    å¯¹è®­ç»ƒå’ŒéªŒè¯æ•°æ®è¿›è¡Œå½’ä¸€åŒ–
    
    Args:
        train_data: è®­ç»ƒæ•°æ® (n_samples, seq_len, n_features)
        val_data: éªŒè¯æ•°æ® (n_samples, seq_len, n_features) 
        method: å½’ä¸€åŒ–æ–¹æ³• ('standard', 'minmax', 'robust')
    
    Returns:
        normalized_train_data, normalized_val_data, scaler
    """
    # è·å–åŸå§‹å½¢çŠ¶
    train_shape = train_data.shape
    val_shape = val_data.shape
    
    # é‡å¡‘ä¸º2D: (n_samples * seq_len, n_features)
    train_reshaped = train_data.reshape(-1, train_shape[-1])
    val_reshaped = val_data.reshape(-1, val_shape[-1])
    
    # é€‰æ‹©å½’ä¸€åŒ–æ–¹æ³•
    if method == 'standard':
        scaler = StandardScaler()  # æ ‡å‡†åŒ–: å‡å€¼0ï¼Œæ ‡å‡†å·®1
    elif method == 'minmax':
        scaler = MinMaxScaler()    # æœ€å°-æœ€å¤§ç¼©æ”¾: èŒƒå›´[0,1]
    elif method == 'robust':
        scaler = RobustScaler()    # é²æ£’ç¼©æ”¾: ä½¿ç”¨ä¸­ä½æ•°å’Œå››åˆ†ä½æ•°
    else:
        raise ValueError("method must be 'standard', 'minmax', or 'robust'")
    
    # åœ¨è®­ç»ƒæ•°æ®ä¸Šæ‹Ÿåˆscalerï¼Œç„¶åå˜æ¢è®­ç»ƒå’ŒéªŒè¯æ•°æ®
    train_normalized = scaler.fit_transform(train_reshaped)
    val_normalized = scaler.transform(val_reshaped)
    
    # é‡å¡‘å›åŸå§‹å½¢çŠ¶
    train_normalized = train_normalized.reshape(train_shape)
    val_normalized = val_normalized.reshape(val_shape)
    
    return train_normalized, val_normalized, scaler


if __name__ == '__main__':
    seq_len = 20
    n_features = 7
    batch_size = 128
    # =================== 1. æ•°æ®åŠ è½½ ===================
    train_data = pd.read_csv(
        "/work/ai/WHOAMI/train_data/vital_sleep_classifier/out.csv",
        usecols=["breath_line", "heart_line", "breath_bpm", "heart_bpm", "distance", "signal_intensity", "state"]
    )
    train_data = np.array(train_data)
    train_data = create_sequences(train_data, seq_len, n_features, slide_window_flag=1)
    print(train_data.shape)
    # =================== 1. æ•°æ®åŠ è½½ ===================
    
    # =================== 2. æ•°æ®åˆ†å‰² ===================
    train_data, val_data = time_series_split(train_data)
    # =================== 2. æ•°æ®åˆ†å‰² ===================

    # =================== 3. å½’ä¸€åŒ– â­ ===================
    # å½’ä¸€åŒ–æ•°æ®
    train_data, val_data, scaler = normalize_data(
        train_data, 
        val_data, 
        method='standard'  # å¯é€‰æ‹©: 'standard', 'minmax', 'robust'
    )
    import joblib
    # ğŸ†• æ·»åŠ è¿™éƒ¨åˆ†æ¥ä¿å­˜scaler
    scaler_save_path = 'training_scaler.pkl'
    joblib.dump(scaler, scaler_save_path)
    print(f"âœ… å½’ä¸€åŒ–å™¨å·²ä¿å­˜åˆ°: {scaler_save_path}")
    # =================== 3. å½’ä¸€åŒ– â­ ===================
    
    
    # =================== 4. è½¬æ¢ä¸ºå¼ é‡ ===================
    train_data = torch.tensor(train_data, dtype=torch.float32)
    val_data = torch.tensor(val_data, dtype=torch.float32)
    # =================== 4. è½¬æ¢ä¸ºå¼ é‡ ===================
    
    # =================== 5. åˆ›å»ºDataLoader ===================
    train_loader, val_loader = create_data_loaders(
        train_data, val_data, batch_size=batch_size
    )
    # =================== 5. åˆ›å»ºDataLoader ===================
    
    
    model = RecurrentAutoencoder(
        seq_len=seq_len, 
        n_features=n_features, 
        embedding_dim=128
    )
    
    model = model.to(device)
    
    model, history = train_model(
        model, 
        train_loader, 
        val_loader, 
        n_epochs=150
    )
