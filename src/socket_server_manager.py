#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@Time Â  Â : 2025/08/22 09:22
@Author Â : weiyutao
@File Â  Â : socket_server_manager.py
"""
import time
import threading
from typing import (
    Optional,
    List
    
)


from .base.producer_consumer_manager import ProducerConsumerManager
from .socket_server import SocketServer
from .base.consumer_tool_pool import ConsumerToolPool
from agent.base.base_tool import tool


@tool
class ExampleSocketServerManager(ProducerConsumerManager):
    """ç¤ºä¾‹å®ç°ï¼šæ¨¡æ‹ŸSocketServerManager"""
    injected_data: Optional[List] = None

    def __init__(
        self,
        max_producers=20, 
        max_consumers=30, 
        production_queue_size=1000, 
        consumer_tool_pool: ConsumerToolPool = None,
        use_redis=False,
        redis_config=None,
        device_storage_type='memory',  # 'memory', 'redis', 'hybrid'
        device_storage_redis_config=None,
        device_max_queue_size=60,
        injected_data: Optional[List] = None,
    ):
        self.injected_data = injected_data
        self.socket_servers = {}
        self.init(
            max_producers=max_producers,
            max_consumers=max_consumers,
            production_queue_size=production_queue_size,
            consumer_tool_pool=consumer_tool_pool,
            use_redis=use_redis,
            redis_config=redis_config,
            device_storage_type=device_storage_type,
            device_storage_redis_config=device_storage_redis_config,
            device_max_queue_size=device_max_queue_size
        )


    def _classify_and_store_data(self, parse_data):
        """
        æ•°æ®åˆ†ç±»å­˜å‚¨åˆ°å›ºå®šå¤§å°æ»‘åŠ¨é˜Ÿåˆ—
        Args:
            parse_data: è§£æåçš„æ•°æ®ï¼Œæœ€åä¸€ä¸ªå…ƒç´ æ˜¯device_id
        """
        device_id = parse_data[-1]
        # 2. åŒæ—¶å­˜å‚¨åˆ°è®¾å¤‡ä¸“ç”¨é˜Ÿåˆ—ï¼ˆ60ç§’æ•°æ®ç¼“å­˜ï¼‰
        self.put_device_data(device_id, parse_data)
        devices = self.get_all_devices()
        self.logger.info(f"devices: {devices}, \n {self.get_all_device_data(devices[0])}")


    def start_socket_server(self, port: int):
        if port in self.socket_servers:
            self.logger.warning(f"Socket server on port {port} already exists")
            return
        production_id = f"socket_server_{port}"

        self.production_line_locks[production_id] = threading.Lock()

        self.production_line_stop_flags[production_id] = False
        socket_server = SocketServer(
            port=port,
            data_callback=self._classify_and_store_data,
            injected_data=self.injected_data,
        )
        socket_server.start()
        self.socket_servers[port] = socket_server
        self.active_production_lines[production_id] = {
            'port': port,
            'socket_server': socket_server
        }
        self.logger.info(f"Started socket server on port {port} with production ID {production_id}")


    def start_produce_worker(self, port: int, *args, **kwargs):
        self.start_socket_server(port=port)


    def stop_produce_worker(self, production_id):
        """åœæ­¢ç‰¹å®šçš„ç”Ÿäº§è€…"""
        if production_id in self.active_production_lines:
            future = self.active_production_lines[production_id]
            if not future.done():
                future.cancel()
            del self.active_production_lines[production_id]
            self.logger.info(f"åœæ­¢ç”Ÿäº§è€…: {production_id}")


    def _process_stored_device_data(self):
        """å¤„ç†å­˜å‚¨åœ¨è®¾å¤‡é˜Ÿåˆ—ä¸­çš„æ•°æ®"""
        try:
            # è·å–æ‰€æœ‰è®¾å¤‡ID
            devices = self.get_all_devices()
            for device_id in devices:
                device_data_list = self.get_all_device_data(device_id)
                self.logger.info(f"{device_id}: ------------------ \n {len(device_data_list)}")
                
                """
                æ‰¹æ¬¡å®æ—¶æ•°æ®å¤„ç†ç®¡é“
                batch_result = pipline(batch_device_data)
                æ‰¹æ¬¡æ’å…¥å®æ—¶æ•°æ®
                """
                
                """
                æ’å…¥å®æ—¶æ•°æ®æµ‹è¯•
                self.real_time_data_state.put([{"device_id": device_data_list[-1][-1], "data": device_data_list[-1]}])
                self.logger.info(f"real_time_data_state: --------------- {self.real_time_data_state.get_all_devices_data()}")
                device_data = self.real_time_data_state.get(device_id="13271C9D10004071111715B507")
                self.logger.info(f"13271C9D10004071111715B507 data: --------------- {device_data}")
                device_UNKNOWN_data = self.real_time_data_state.get(device_id="UNKNOWN")
                self.logger.info(f"UNKNOWN data: --------------- {device_UNKNOWN_data}")
                """
        except Exception as e:
            self.logger.error(f"å¤„ç†å­˜å‚¨è®¾å¤‡æ•°æ®æ—¶å‡ºé”™: {e}")



    def batch_pipline(self):
        ...


    def _start_consumer_worker(self):
        """å®ç°æ¶ˆè´¹è€…å·¥ä½œé€»è¾‘"""
        while self.consumer_worker_running and self._is_running:
            self._process_stored_device_data()


    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨"""
        self.logger.info("å…³é—­SocketServerManager...")
        
        self._is_running = False
        self.consumer_worker_running = False
        
        # åœæ­¢æ‰€æœ‰ç”Ÿäº§è€…
        for production_id in list(self.active_production_lines.keys()):
            self.stop_produce_worker(production_id)
        
        if self.consumer_worker_thread:
            self.consumer_worker_thread.join(timeout=5)
        
        if self.producer_pool:
            self.producer_pool.shutdown(wait=True)
        
        if self.consumer_pool:
            self.consumer_pool.shutdown(wait=True)
        
        self.logger.info("å…³é—­å®Œæˆ")


def demo_usage():
    """æ¼”ç¤ºä¸åŒé…ç½®çš„ä½¿ç”¨æ–¹å¼"""
    
    print("ğŸš€ ProducerConsumerManager è®¾å¤‡å­˜å‚¨æ¼”ç¤º")
    print("=" * 60)
    from .base.rnn_model_info import RNNModelInfo
    from ..neural_network.rnn.model import LSTM
    from .config.detector_config import DetectorConfig
    from agent.config.sql_config import SqlConfig
    from pathlib import Path
    
    DETECT_CONFIG_PATH = "/work/ai/real_time_vital_analyze/config/yaml/detect_config.yaml"
    REDIS_CONFIG_PATH = "/work/ai/real_time_vital_analyze/config/yaml/redis.yaml"
    
    CONFIG = DetectorConfig.from_file(DETECT_CONFIG_PATH).__dict__
    
    
    
    redis_config = SqlConfig.from_file(Path(REDIS_CONFIG_PATH))
    TOPIC_DICT = CONFIG['topics']
    conf_dict = CONFIG["conf"]
    model_path_dict = CONFIG["model_path"]
    class_list_dict = CONFIG["class_list"]
    topic_list = TOPIC_DICT
    model_paths = {}
    
    for conf_key, conf_value in conf_dict.items():
        for topic_name in topic_list:
            topic_key = conf_key + topic_name
            model_paths[topic_key] = RNNModelInfo(
                model_path="/work/ai/whoami/"+model_path_dict[topic_name],
                model_type_class=LSTM,
                classes=class_list_dict[topic_name],
                conf=conf_value[topic_name]
            )
    print(f"model_paths: --------------------------------------\n {model_paths}")
    consumer_tool_pool = ConsumerToolPool(model_paths=model_paths)
    
    
    # é…ç½®1: ç”Ÿäº§é˜Ÿåˆ—ä½¿ç”¨å†…å­˜ï¼Œè®¾å¤‡å­˜å‚¨ä½¿ç”¨å†…å­˜
    print("\nğŸ“¦ é…ç½®1: å…¨å†…å­˜å­˜å‚¨")
    manager1 = ExampleSocketServerManager(
        max_producers=5,
        max_consumers=2,
        production_queue_size=100,
        consumer_tool_pool=consumer_tool_pool,
        use_redis=False,  # ç”Ÿäº§é˜Ÿåˆ—ä½¿ç”¨å†…å­˜
        redis_config=redis_config,
        device_storage_type='redis'  # è®¾å¤‡å­˜å‚¨ä½¿ç”¨å†…å­˜
    )
    
    
    # å¯åŠ¨ç”Ÿäº§è€…
    manager1.start_produce_worker(port=8002)
    
    # ç­‰å¾…ä¸€æ®µæ—¶é—´
    # time.sleep(2)
    
    # æŸ¥çœ‹è®¾å¤‡æ•°æ®
    devices = manager1.get_all_devices()
    print(f"æ‰€æœ‰è®¾å¤‡: {devices}")
    
    for device_id in devices[:2]:  # åªçœ‹å‰2ä¸ªè®¾å¤‡
        queue_size = manager1.get_device_queue_size(device_id)
        print(f"è®¾å¤‡ {device_id} é˜Ÿåˆ—å¤§å°: {queue_size}")
    time.sleep(1000000)
    # manager1.shutdown()
    
    # é…ç½®2: ç”Ÿäº§é˜Ÿåˆ—ä½¿ç”¨å†…å­˜ï¼Œè®¾å¤‡å­˜å‚¨ä½¿ç”¨Redis
    # print("\nğŸ”„ é…ç½®2: ç”Ÿäº§é˜Ÿåˆ—å†…å­˜ + è®¾å¤‡å­˜å‚¨Redis")
    # try:
    #     manager2 = ExampleSocketServerManager()
    #     manager2.init(
    #         max_producers=5,
    #         max_consumers=2,
    #         production_queue_size=100,
    #         consumer_tool_pool=None,
    #         use_redis=False,  # ç”Ÿäº§é˜Ÿåˆ—ä½¿ç”¨å†…å­˜
    #         device_storage_type='redis',  # è®¾å¤‡å­˜å‚¨ä½¿ç”¨Redis
    #         device_storage_redis_config={
    #             'host': 'localhost',
    #             'port': 6379,
    #             'database': 0,
    #             'key_prefix': 'device_queue_demo'
    #         }
    #     )
        
    #     manager2._start_consumer_worker()
    #     producer_id = manager2.start_produce_worker("socket_source_2")
        
    #     time.sleep(2)
        
    #     stats = manager2.get_comprehensive_stats()
    #     print(f"ç»Ÿè®¡ä¿¡æ¯: {json.dumps(stats, indent=2, ensure_ascii=False)}")
        
    #     manager2.shutdown()
        
    # except Exception as e:
    #     print(f"Redisé…ç½®å¤±è´¥: {e}")
    
    # # é…ç½®3: æ··åˆé…ç½®æ¼”ç¤º
    # print("\nğŸ¯ é…ç½®3: æ··åˆå­˜å‚¨æ¼”ç¤º")
    # try:
    #     manager3 = ExampleSocketServerManager()
    #     manager3.init(
    #         max_producers=5,
    #         max_consumers=2,
    #         production_queue_size=100,
    #         consumer_tool_pool=None,
    #         use_redis=True,  # ç”Ÿäº§é˜Ÿåˆ—ä½¿ç”¨Redis
    #         redis_config={
    #             'host': 'localhost',
    #             'port': 6379,
    #             'database': 1,  # ä¸åŒçš„æ•°æ®åº“
    #         },
    #         device_storage_type='hybrid',  # è®¾å¤‡å­˜å‚¨ä½¿ç”¨æ··åˆæ¨¡å¼
    #         device_storage_redis_config={
    #             'host': 'localhost',
    #             'port': 6379,
    #             'database': 2,  # è®¾å¤‡å­˜å‚¨ç”¨ä¸åŒæ•°æ®åº“
    #             'key_prefix': 'hybrid_device_queue'
    #         }
    #     )
        
    #     manager3._start_consumer_worker()
    #     producer_id = manager3.start_produce_worker("socket_source_3")
        
    #     time.sleep(2)
        
    #     stats = manager3.get_comprehensive_stats()
    #     print(f"ç»Ÿè®¡ä¿¡æ¯: {json.dumps(stats, indent=2, ensure_ascii=False)}")
        
    #     # æ¼”ç¤ºè¿è¡Œæ—¶åˆ‡æ¢å­˜å‚¨
    #     print("\nğŸ”„ æ¼”ç¤ºè®¾å¤‡å­˜å‚¨åˆ‡æ¢...")
    #     success = manager3.switch_device_storage('memory')
    #     print(f"åˆ‡æ¢åˆ°å†…å­˜å­˜å‚¨: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
    #     if success:
    #         stats_after = manager3.get_comprehensive_stats()
    #         print(f"åˆ‡æ¢åç»Ÿè®¡: {stats_after['device_storage']}")
        
    #     manager3.shutdown()
        
    # except Exception as e:
    #     print(f"æ··åˆé…ç½®å¤±è´¥: {e}")


if __name__ == "__main__":
    # ExampleSocketServerManager(
    #     max_producers=5,
    #         max_consumers=2,
    #         production_queue_size=100,
    #         consumer_tool_pool=None,
    #         use_redis=True,  # ç”Ÿäº§é˜Ÿåˆ—ä½¿ç”¨Redis
    #         redis_config={
    #             'host': 'localhost',
    #             'port': 6379,
    #             'database': 1,  # ä¸åŒçš„æ•°æ®åº“
    #         },
    #         device_storage_type='hybrid',  # è®¾å¤‡å­˜å‚¨ä½¿ç”¨æ··åˆæ¨¡å¼
    #         device_storage_redis_config={
    #             'host': 'localhost',
    #             'port': 6379,
    #             'database': 2,  # è®¾å¤‡å­˜å‚¨ç”¨ä¸åŒæ•°æ®åº“
    #             'key_prefix': 'hybrid_device_queue'
    #         }
    # )

    demo_usage()